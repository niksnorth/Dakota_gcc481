Blurb::
Morris One-at-a-Time
Description::

The Morris One-At-A-Time (MOAT) method, originally proposed by Morris
\cite Mor91, is a screening method, designed
to explore a computational model to distinguish between input
variables that have negligible, linear and additive, or nonlinear or
interaction effects on the output. The computer experiments performed
consist of individually randomized designs which vary one input factor
at a time to create a sample of its elementary effects. 

The number of samples (\c samples) must be a positive integer multiple
of (number of continuous design variable + 1) and will be
automatically adjusted if misspecified. 

The number of partitions (\c
partitions) applies to each variable being studied and must be odd
(the number of MOAT levels per variable is partitions + 1). This will
also be adjusted at runtime as necessary. 

For information on practical use of this method, see 
\cite Sal04. 

Topics::	package_psuade, design_and_analysis_of_computer_experiments
Examples::
Theory::
With MOAT, each dimension of a \f$k-\f$dimensional input space is
uniformly partitioned into \f$p\f$ levels, creating a grid of \f$p^k\f$ points
\f${\bf x} \in \bf{R}^k\f$ at which evaluations of the model \f$y({\bf
x})\f$ might take place. An elementary effect corresponding to input
\f$i\f$ is computed by a forward difference
\f[
d_i({\bf x}) = \frac{y({\bf x} + \Delta {\bf e}_i) - y({\bf x})}{\Delta},
\f]
where \f$e_i\f$ is the \f$i^{\mbox{\scriptsize th}}\f$ coordinate vector, and
the step \f$\Delta\f$ is typically taken to be large (this is not intended
to be a local derivative approximation). In the present
implementation of MOAT, for an input variable scaled to \f$[0,1]\f$,
\f$\Delta = \frac{p}{2(p-1)}\f$, so the step used to find elementary
effects is slightly larger than half the input range.

The distribution of elementary effects \f$d_i\f$ over the input space
characterizes the effect of input \f$i\f$ on the output of interest.
After generating \f$r\f$ samples from this distribution, their mean,
\f[ \mu_i = \frac{1}{r}\sum_{j=1}^{r}{d_i^{(j)}}\f]
modified mean
\f[
\mu_i^* = \frac{1}{r}\sum_{j=1}^{r}{|d_i^{(j)}|},
\f]
(using absolute value) and standard deviation
\f[
\sigma_i = \sqrt{ \frac{1}{r}\sum_{j=1}^{r}{ \left(d_i^{(j)} - \mu_i
\right)^2} }
\f]
are computed for each input \f$i\f$. The mean and modified mean give an
indication of the overall effect of an input on the output. Standard
deviation indicates nonlinear effects or interactions, since it is an
indicator of elementary effects varying throughout the input space.

Faq::
